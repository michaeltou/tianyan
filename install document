1. this is to set root password:
   sudo passwd

2. install ssh command:
    sudo apt-get install openssh-server

3.
    sudo addgroup hadoop  
    sudo adduser -ingroup hadoop hadoop

4.   输入：sudo gedit /etc/sudoers

 回车，打开sudoers文件 
 给hadoop用户赋予和root用户同样的权限 

5. install git.
sudo apt-get install git 

git config --global user.name "michaeltou"
git config --global user.email toudf64_43jhv@163.com


mkdir ..
cd ..
git init
touch README
git add README
git commit -m 'first commit'
git remote add origin git@github.com:xxx/xxxxx.git
git push -u origin master


6、安装ssh

sudo apt-get install openssh-server
  
安装完成后，启动服务

sudo /etc/init.d/ssh start
 
查看服务是否正确启动：ps -e | grep ssh
 
7.
设置免密码登录，生成私钥和公钥

switch to user hadoop, execute following command:

ssh-keygen -t rsa -P ""



cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

chmod 600 ~/.ssh/authorized_keys
chmod 700 ~/.ssh

8.
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

9. install jdk.

  cp jdk jar to /usr/local/
  tar -xvzf *.jar 

10. install hadoop
cp jdk jar to /usr/local/
  tar -xvzf *.jar 
11. install scala


cp jdk jar to /usr/local/
  tar -xvzf *.jar 
12. install spark.

cp jdk jar to /usr/local/
  tar -xvzf *.jar 

12. edit  /etc/profile
   add following configuration:
   
#this is for java start by michael tou
export JAVA_HOME=/usr/local/jdk
export JRE_HOME=/usr/local/jdk/jre
export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JRE_HOME/lib
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
#this is for java end by michael tou

#this is for hadoop start
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
#this is for hadoop end

export PS1='[\u]\$:'


#this is for scala start
export PATH=$PATH:/usr/local/scala/bin
#this is for scala end

#this is for spark start
export PATH=$PATH:/usr/local/spark/bin
export SPARK_HOME=/usr/local/spark
#this is for spark end


#this is for sbit start 
export SBIT_HOME=/usr/local/sbit
export PATH=$PATH:$SBIT_HOME/launchbin
#this is for sbit end


#this is for maven start

export MAVEN_HOME=/usr/local/maven
export MAVEN_BIN=/usr/local/maven/bin
export PATH=$MAVEN_BIN:$PATH


#this is for maven end


13. edit /etc/hosts
 
  add all the know host.

vi /etc/hosts

  192.168.0.61 hadoop1
 192.168.0.62 hadoop2
 192.168.0.63 hadoop3


 
14. 在 Hadoop 目录下创建子目录

$cd /usr/local/hadoop/
$mkdir tmp
$mkdir name
$mkdir data

